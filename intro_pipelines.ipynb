{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines: Or How I Learned to Stop Duplicating Work and Love the Convenience of Storing Multiple Steps in a Single Object\n",
    "\n",
    "Date: October 6, 2019\n",
    "\n",
    "Written by: Cristian E. Nuno\n",
    "\n",
    "![kid transformer](visuals/transformer.gif)\n",
    "\n",
    "### Definition of a pipeline\n",
    "\n",
    "We'll store these steps in a `Pipeline` object. From the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn-pipeline-pipeline):\n",
    "\n",
    "> The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. [The `Pipeline` object] sequentially applies a list of transforms and a final estimator. Intermediate steps of the pipeline must be ‘transforms’ (i.e. transformers), that is, they must implement fit and transform methods. \n",
    "\n",
    "### Broad generalization of a pipeline\n",
    "\n",
    "The key here is we need to specify a specific column, pass it's \"transformer\" (i.e. `SimpleImputer`, `OneHotEncoder`, `StandardScaler`), and determine if the transformation belongs in it's own new column or if it's more appropriate for the transformed column to overwrite the input column.\n",
    "\n",
    "### Benefits of the `Pipeline`\n",
    "\n",
    "From the [User Guide](https://scikit-learn.org/stable/modules/compose.html#pipeline-chaining-estimators):\n",
    "> * **Convenience and encapsulation**\n",
    ">     + You only have to call fit and predict once on your data to fit a whole sequence of estimators.\n",
    "> * **Joint parameter selection**\n",
    ">     + You can grid search over parameters of all estimators in the pipeline at once.\n",
    "> * **Safety**\n",
    ">     + Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors. \n",
    "\n",
    "Here, we'll create a few `Pipeline` objects to do the following:\n",
    "\n",
    "* flag which records contain `NaN` values in the `sepal_length` and `sepal_width` features;\n",
    "* impute the median value for `NaN` values in the `sepal_length` and `sepal_width` features; and\n",
    "* return all other columns - `petal_length` & `petal_width` - as is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load iris data set\n",
    "iris = load_iris()\n",
    "\n",
    "# load feature matrix\n",
    "X = iris[\"data\"]\n",
    "# load target vector\n",
    "y = iris[\"target\"]\n",
    "\n",
    "# standardize feature names spelling and casing\n",
    "feature_names = [col.replace(\" \", \"_\").replace(\"_(cm)\", \"\") \n",
    "                 for col in (iris[\"feature_names\"] + [\"species\"])]\n",
    "\n",
    "# transform X and y into data frame\n",
    "iris_df = pd.DataFrame(np.column_stack((X, y.reshape(-1, 1)))\n",
    "                       , columns=feature_names)\n",
    "\n",
    "# convert species from numeric to categorical\n",
    "class_names = {0.0: \"setosa\", 1.0: \"versicolor\", 2.0: \"virginica\"}\n",
    "iris_df[\"species\"] = iris_df[\"species\"].map(class_names)\n",
    "\n",
    "# show first few records\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For educational purposes only, let's replace some values with `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          NaN           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa\n",
       "5           5.4          3.9           1.7          0.4  setosa\n",
       "6           4.6          3.4           1.4          0.3  setosa\n",
       "7           5.0          3.4           1.5          0.2  setosa\n",
       "8           NaN          NaN           1.4          0.2  setosa\n",
       "9           4.9          3.1           1.5          0.1  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize random number generator\n",
    "random.seed(2019)\n",
    "\n",
    "# generate list of random integers \n",
    "random_ints = [random.randrange(0, len(iris_df)) for _ in range(20)]\n",
    "\n",
    "# for these random index values, replace their real values with NaN\n",
    "iris_df.loc[random_ints, \"sepal_length\"] = np.nan\n",
    "iris_df.loc[random_ints, \"sepal_width\"] = np.nan\n",
    "\n",
    "# manually force the first \"sepal_width\" value to also be NaN\n",
    "iris_df.loc[0, \"sepal_width\"] = np.nan\n",
    "\n",
    "iris_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split `iris_df` into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris_df.drop(\"species\", axis=1),\n",
    "                                                    iris_df[\"species\"],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create custom transformer that identifies records that have `NaN` values\n",
    "\n",
    "Sometimes we need to add new features to our existing feature space. In this case, we can't rely on importing a traditional transformer (i.e. `StandardScaler`, `OneHotEncoder`, etc.).\n",
    "\n",
    "Instead, we'll need to create our own custom transformer. We will do this by creating a new class that implements both `.fit()` and `.transform()` methods. \n",
    "\n",
    "_Shoutout to [Sebastian Raschka](https://sebastianraschka.com/) for helping me out on [Twitter](https://twitter.com/cenuno_/status/1179855832374099968) to figure this out!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsMissing(BaseEstimator):\n",
    "    \"\"\"Creates a new column flagging if any values from one column are missing\n",
    "    \n",
    "    Note: this class will be used inside a scikit-learn Pipeline\n",
    "    \n",
    "    Attributes:\n",
    "        col_name (str): name of a column\n",
    "        \n",
    "    Methods:\n",
    "        _is_missing(): returns 1 if record contains NaN value; 0 if else\n",
    "        \n",
    "        fit(): fit all the transformers one after the other \n",
    "               then fit the transformed data using the final estimator\n",
    "               \n",
    "        transform(): apply transformers, and transform with the final estimator\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, col_name):\n",
    "        self.col_name = col_name\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _is_missing(self, X):\n",
    "        \"\"\"Flag if a record has a NaN value\"\"\"\n",
    "        if pd.isna(X):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Copies X and creates a new column before returning X_new\"\"\"\n",
    "        new_col = self.col_name + \"_missing\"\n",
    "        X_new = X.copy()\n",
    "        X_new[new_col] = X_new[self.col_name].apply(self._is_missing)\n",
    "        return X_new\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create first `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_mapper = Pipeline(steps=[\n",
    "    (\"missing_sl\", IsMissing(col_name=\"sepal_length\")),\n",
    "    (\"missing_sw\", IsMissing(col_name=\"sepal_width\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>sepal_length_missing</th>\n",
       "      <th>sepal_width_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  \\\n",
       "73            6.1          2.8           4.7          1.2   \n",
       "30            4.8          3.1           1.6          0.2   \n",
       "98            5.1          2.5           3.0          1.1   \n",
       "36            5.5          3.5           1.3          0.2   \n",
       "1             4.9          3.0           1.4          0.2   \n",
       "149           5.9          3.0           5.1          1.8   \n",
       "4             5.0          3.6           1.4          0.2   \n",
       "100           6.3          3.3           6.0          2.5   \n",
       "64            5.6          2.9           3.6          1.3   \n",
       "135           7.7          3.0           6.1          2.3   \n",
       "5             5.4          3.9           1.7          0.4   \n",
       "48            5.3          3.7           1.5          0.2   \n",
       "132           6.4          2.8           5.6          2.2   \n",
       "39            NaN          NaN           1.5          0.2   \n",
       "69            NaN          NaN           3.9          1.1   \n",
       "\n",
       "     sepal_length_missing  sepal_width_missing  \n",
       "73                      0                    0  \n",
       "30                      0                    0  \n",
       "98                      0                    0  \n",
       "36                      0                    0  \n",
       "1                       0                    0  \n",
       "149                     0                    0  \n",
       "4                       0                    0  \n",
       "100                     0                    0  \n",
       "64                      0                    0  \n",
       "135                     0                    0  \n",
       "5                       0                    0  \n",
       "48                      0                    0  \n",
       "132                     0                    0  \n",
       "39                      1                    1  \n",
       "69                      1                    1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_mapper.fit(X_train).transform(X_train).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a pipeline to impute the median values for `sepal_length` and `sepal_width`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median value for sepal length: 5.75\n",
      "Median value for sepal width: 3.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Median value for sepal length: {iris_df['sepal_length'].median()}\")\n",
    "print(f\"Median value for sepal width: {iris_df['sepal_width'].median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_mapper = ColumnTransformer(transformers=[\n",
    "    (\"impute\", SimpleImputer(missing_values=np.nan, strategy=\"median\"), ['sepal_length', 'sepal_width'])\n",
    "],\n",
    "                      remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: we're setting `remainder` to \"passthrough\" so that all non `sepal_length` and `sepal_width` columns are returned without any transformations_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.1, 2.8, 4.7, 1.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [5.9, 3. , 5.1, 1.8],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [5.7, 3. , 1.5, 0.2],\n",
       "       [5.7, 3. , 3.9, 1.1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute_mapper.fit(X_train).transform(X_train)[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, notice the 14 and 15th records: they were previously `NaN`. After using the `SimpleImputer` transformer, the `NaN` values were replaced with the median values of `sepal_length` and `sepal_width`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the two pipelines into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_mapper = Pipeline(steps=[\n",
    "    (\"missing\", missing_mapper),\n",
    "    (\"impute\", impute_mapper)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.1, 2.8, 4.7, 1.2, 0. , 0. ],\n",
       "       [4.8, 3.1, 1.6, 0.2, 0. , 0. ],\n",
       "       [5.1, 2.5, 3. , 1.1, 0. , 0. ],\n",
       "       [5.5, 3.5, 1.3, 0.2, 0. , 0. ],\n",
       "       [4.9, 3. , 1.4, 0.2, 0. , 0. ],\n",
       "       [5.9, 3. , 5.1, 1.8, 0. , 0. ],\n",
       "       [5. , 3.6, 1.4, 0.2, 0. , 0. ],\n",
       "       [6.3, 3.3, 6. , 2.5, 0. , 0. ],\n",
       "       [5.6, 2.9, 3.6, 1.3, 0. , 0. ],\n",
       "       [7.7, 3. , 6.1, 2.3, 0. , 0. ],\n",
       "       [5.4, 3.9, 1.7, 0.4, 0. , 0. ],\n",
       "       [5.3, 3.7, 1.5, 0.2, 0. , 0. ],\n",
       "       [6.4, 2.8, 5.6, 2.2, 0. , 0. ],\n",
       "       [5.7, 3. , 1.5, 0.2, 1. , 1. ],\n",
       "       [5.7, 3. , 3.9, 1.1, 1. , 1. ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prep_mapper.fit(X_train).transform(X_train)[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's take this up by perfoming all the preprocessing steps prior to building a `DecisionTreeClassifier` model\n",
    "\n",
    "This model will help us classify which species a flower is from `X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=2019,\n",
    "                                min_samples_leaf=30,\n",
    "                                criterion=\"gini\",\n",
    "                                min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"dataprep\", data_prep_mapper),\n",
    "    (\"model\", dt_clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit `X_train` and `y_train` onto the `pipe` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('dataprep',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('missing',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('missing_sl',\n",
       "                                                   IsMissing(col_name='sepal_length')),\n",
       "                                                  ('missing_sw',\n",
       "                                                   IsMissing(col_name='sepal_width'))],\n",
       "                                           verbose=False)),\n",
       "                                 ('impute',\n",
       "                                  ColumnTransformer(n_jobs=None,\n",
       "                                                    remainder='passthrough',\n",
       "                                                    sparse_threshold=0.3,\n",
       "                                                    transformer_weights=None,\n",
       "                                                    transformers=[('i...\n",
       "                                                                    'sepal_width'])],\n",
       "                                                    verbose=False))],\n",
       "                          verbose=False)),\n",
       "                ('model',\n",
       "                 DecisionTreeClassifier(class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features=None,\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=30,\n",
       "                                        min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort=False, random_state=2019,\n",
       "                                        splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `pipe` object to make predictions on `X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the first 10 predictions of our multi-class classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'setosa', 'virginica', 'versicolor', 'virginica',\n",
       "       'setosa', 'virginica', 'setosa', 'versicolor', 'virginica'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42         setosa\n",
       "20         setosa\n",
       "124     virginica\n",
       "87     versicolor\n",
       "107     virginica\n",
       "40         setosa\n",
       "111     virginica\n",
       "46         setosa\n",
       "84     versicolor\n",
       "147     virginica\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You now know how to take advantage of `Pipeline` objects to stop duplicating your preprocessing steps in the training and testing sets. I hope this helps you take advantage of yet another module built into `scikit-learn` to help improve your machine learning workflow!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline-env",
   "language": "python",
   "name": "pipeline-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
